{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ac26da2-8b67-4580-bed2-950ab5f3631a",
   "metadata": {},
   "source": [
    "## Customer Segmentation with Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa7c323-0468-46c0-ba66-a58f64d35edc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "\n",
    "Customer segmentation models help businesses divide their customer base into different groups based on shared behaviors or characteristics. This kind of grouping allows companies to tailor their marketing and sales strategies more effectively.\n",
    "\n",
    "Here‚Äôs a simple example to illustrate how data segmentation can drive sales:\n",
    "\n",
    "> Whenever I browse an e-commerce website, I‚Äôm always on the lookout for discounts.  \n",
    "> If I find a clothing item I like but it‚Äôs not on sale, I usually wait until there‚Äôs a special offer before I make a purchase.\n",
    "\n",
    "E-commerce data scientists build segmentation models to uncover patterns like this. Using these models, they can identify shoppers who consistently wait for discounts‚Äîpeople like me.  \n",
    "They often place us into a segment known as **‚Äúthrifty shoppers.‚Äù**\n",
    "\n",
    "Once a new promotion is live, the marketing team sends personalized ads to everyone in this segment, highlighting affordability and discounts.  \n",
    "I usually end up buying everything I need during the promotion window‚Äîjust like many others in my segment‚Äîwhich boosts the company‚Äôs sales.\n",
    "\n",
    "This kind of targeted approach is applied across all customer groups, with tailored promotions based on each group‚Äôs purchase behavior.\n",
    "\n",
    "---\n",
    "\n",
    "Segmentation like this is typically done using **unsupervised machine learning** techniques such as:\n",
    "\n",
    "- **K-Means Clustering**\n",
    "- **Hierarchical Clustering**\n",
    "\n",
    "These models detect patterns in customer behavior that may not be obvious at first glance.\n",
    "\n",
    "---\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "In this notebook, we‚Äôll walk through:\n",
    "\n",
    "- How to clean and prepare data for customer segmentation\n",
    "- How to implement a **K-Means algorithm from scratch**\n",
    "- How to use **RFM (Recency, Frequency, Monetary)** analysis to assess customer value\n",
    "- How to evaluate clustering performance using relevant metrics\n",
    "- How to **visualize and interpret customer clusters**\n",
    "\n",
    "Let‚Äôs get started!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a543e0de-ab31-4ca8-83ad-e6694e5787e4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üìö Table of Contents\n",
    "\n",
    "1. [Prerequisites for Building a Customer Segmentation Model](#prerequisites-for-building-a-customer-segmentation-model)\n",
    "2. [Understanding the Segmentation Data](#understanding-the-segmentation-data)\n",
    "3. [Preprocessing Data for Segmentation](#preprocessing-data-for-segmentation)\n",
    "4. [Building the Customer Segmentation Model](#building-the-customer-segmentation-model)\n",
    "5. [Segmentation Model Interpretation and Visualization](#segmentation-model-interpretation-and-visualization)\n",
    "6. [Segmentation Modelling: Next Steps](#segmentation-modelling-next-steps)\n",
    "7. [Summary of Steps: Customer Segmentation with RFM & K-Means](#summary-of-steps-customer-segmentation-with-rfm--k-means)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6711d69-5acc-4ef0-99d4-48a32a68fbe1",
   "metadata": {},
   "source": [
    "## Prerequisites for Building a Customer Segmentation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ce57cf-b5b3-44f9-b46a-6792cd3d8653",
   "metadata": {},
   "source": [
    "\n",
    "In this tutorial, we will use an **E-Commerce Dataset from Kaggle** that contains transaction information from around **4,000 customers**.\n",
    "\n",
    "Before we begin, ensure you have a **Python IDE** installed.  \n",
    "We recommend using **Jupyter Notebook** for a smooth experience ‚Äî it allows you to run code step-by-step and view visualizations inline.\n",
    "\n",
    "### ‚úÖ Required Libraries\n",
    "\n",
    "Make sure the following Python libraries are installed:\n",
    "\n",
    "- `numpy`\n",
    "- `pandas`\n",
    "- `matplotlib`\n",
    "- `seaborn`\n",
    "- `scikit-learn`\n",
    "- `kneed`\n",
    "- `scipy`\n",
    "\n",
    "You can install them via pip if needed:\n",
    "\n",
    "```bash\n",
    "!pip install numpy pandas matplotlib seaborn scikit-learn kneed scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c10662ad-c3df-4618-9d8d-668fa9aa88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install numpy pandas matplotlib seaborn scikit-learn kneed scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb959a39-5f43-47dc-a336-b0993358207c",
   "metadata": {},
   "source": [
    "## Understanding the Segmentation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0459cdf2-9c46-4069-b64f-100546c5703b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Before starting any data science project, it‚Äôs essential to explore the dataset and understand the meaning and importance of each variable.\n",
    "\n",
    "To begin, let's import the **Pandas** library and load the dataset into Python:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv', encoding='unicode_escape')\n",
    "````\n",
    "\n",
    "The `encoding='unicode_escape'` argument is useful for handling special characters that may exist in the dataset (e.g., currency symbols, accented letters).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bccdad5-8365-4671-87bb-0402cec39ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset using the full path\n",
    "df = pd.read_csv(r'C:\\Users\\sarat\\OneDrive\\Documents\\DOCUMENTS\\MS BANA UC\\PROJECTS\\E COMMERCE CUSTOMER SEGMENTATION\\data.csv', \n",
    "                 encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c311b2b-72f6-4f25-9abb-7f91518bcd0c",
   "metadata": {},
   "source": [
    "- Now, let‚Äôs look at the head of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bea00db3-ad84-4d9b-abb7-f0715b436548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536365</td>\n",
       "      <td>85123A</td>\n",
       "      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.55</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>536365</td>\n",
       "      <td>71053</td>\n",
       "      <td>WHITE METAL LANTERN</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>536365</td>\n",
       "      <td>84406B</td>\n",
       "      <td>CREAM CUPID HEARTS COAT HANGER</td>\n",
       "      <td>8</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>2.75</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029G</td>\n",
       "      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>536365</td>\n",
       "      <td>84029E</td>\n",
       "      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n",
       "      <td>6</td>\n",
       "      <td>12/1/2010 8:26</td>\n",
       "      <td>3.39</td>\n",
       "      <td>17850.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode                          Description  Quantity  \\\n",
       "0    536365    85123A   WHITE HANGING HEART T-LIGHT HOLDER         6   \n",
       "1    536365     71053                  WHITE METAL LANTERN         6   \n",
       "2    536365    84406B       CREAM CUPID HEARTS COAT HANGER         8   \n",
       "3    536365    84029G  KNITTED UNION FLAG HOT WATER BOTTLE         6   \n",
       "4    536365    84029E       RED WOOLLY HOTTIE WHITE HEART.         6   \n",
       "\n",
       "      InvoiceDate  UnitPrice  CustomerID         Country  \n",
       "0  12/1/2010 8:26       2.55     17850.0  United Kingdom  \n",
       "1  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "2  12/1/2010 8:26       2.75     17850.0  United Kingdom  \n",
       "3  12/1/2010 8:26       3.39     17850.0  United Kingdom  \n",
       "4  12/1/2010 8:26       3.39     17850.0  United Kingdom  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49da04df-00d6-4aab-ba25-6a6d9385dc61",
   "metadata": {},
   "source": [
    "## RFM Feature Engineering Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaf7956b-ccf5-4f4d-9837-b8681937818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RFM file saved as 'sample_rfm.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ‚úÖ Load raw transactional data from your local path with correct encoding\n",
    "data_path = r\"C:\\Users\\sarat\\OneDrive\\Documents\\DOCUMENTS\\MS BANA UC\\PROJECTS\\E COMMERCE CUSTOMER SEGMENTATION\\data.csv\"\n",
    "df = pd.read_csv(data_path, encoding='ISO-8859-1')  # or use encoding='latin1'\n",
    "\n",
    "# ‚úÖ Preprocessing\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df = df[df['CustomerID'].notnull()]\n",
    "df = df[df['Quantity'] > 0]\n",
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "# ‚úÖ Reference date\n",
    "ref_date = df['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "# ‚úÖ RFM Calculation\n",
    "rfm = df.groupby('CustomerID').agg({\n",
    "    'InvoiceDate': lambda x: (ref_date - x.max()).days,\n",
    "    'InvoiceNo': 'nunique',\n",
    "    'TotalPrice': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "rfm.columns = ['CustomerID', 'Recency', 'Frequency', 'Monetary']\n",
    "rfm = rfm[(rfm['Monetary'] > 0) & (rfm['Frequency'] > 0)]\n",
    "\n",
    "# ‚úÖ Save RFM file\n",
    "rfm.to_csv(\"sample_rfm.csv\", index=False)\n",
    "print(\"‚úÖ RFM file saved as 'sample_rfm.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98e413f-012a-4e79-8406-fd4b0e5b698e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### üìò Data Dictionary\n",
    "\n",
    "- **InvoiceNo**: Unique invoice number assigned to each transaction.\n",
    "- **StockCode**: Unique code for each distinct product.\n",
    "- **Description**: Name/description of the purchased item.\n",
    "- **Quantity**: Number of units purchased per product per invoice.\n",
    "- **InvoiceDate**: Date and time when the transaction occurred.\n",
    "- **UnitPrice**: Price per unit of the product (in local currency).\n",
    "- **CustomerID**: Unique identifier for each customer.\n",
    "- **Country**: Country from which the customer placed the order.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f391d47-ec25-48f8-b218-d7a22e7ef3c7",
   "metadata": {},
   "source": [
    "## Preprocessing Data for Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10425db8-cfab-47ea-9761-2360d81645a5",
   "metadata": {},
   "source": [
    "\n",
    "The raw data we downloaded is quite detailed and not in a format that can be directly used for customer segmentation.  \n",
    "We need to perform **preliminary data preparation** to make the dataset interpretable and modeling-ready.\n",
    "\n",
    "### üîç Key Features for Behavior Analysis\n",
    "\n",
    "The most informative features for understanding customer behavior in this dataset are:\n",
    "\n",
    "- **Quantity**\n",
    "- **InvoiceDate**\n",
    "- **UnitPrice**\n",
    "\n",
    "Using these, we‚Äôll derive a customer‚Äôs **RFM profile**, which stands for:\n",
    "\n",
    "- **Recency**: How recently has the customer made a purchase?\n",
    "- **Frequency**: How often does the customer make purchases?\n",
    "- **Monetary Value**: How much money does the customer spend in total?\n",
    "\n",
    "RFM analysis is a common marketing approach for assessing customer value and identifying high-potential segments.\n",
    "\n",
    "### üßÆ Why RFM?\n",
    "\n",
    "By calculating Recency, Frequency, and Monetary value for each customer in the dataset, we‚Äôll obtain numeric features that reflect behavioral patterns. These features will serve as inputs to our clustering model.\n",
    "\n",
    "Next, we‚Äôll begin transforming the dataset to compute RFM values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b5245-31cb-4da4-9379-9d770a37407f",
   "metadata": {},
   "source": [
    "> Before we can build a segmentation model, we need to transform the raw transactional data into meaningful behavioral metrics using RFM analysis ‚Äî Recency, Frequency, and Monetary Value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12157b55-6eae-4450-a022-8114b49340af",
   "metadata": {},
   "source": [
    "### Recency: Days Since Last Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4defa7cf-4b78-4ebf-8007-03b426ecc0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the full file path string (with raw string to handle backslashes)\n",
    "file_path = r\"C:\\Users\\sarat\\OneDrive\\Documents\\DOCUMENTS\\MS BANA UC\\PROJECTS\\E COMMERCE CUSTOMER SEGMENTATION\\data.csv\\data.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path, encoding='unicode_escape')\n",
    "\n",
    "# Convert InvoiceDate to datetime format\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# Preview the data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0643565b-3507-4f27-a511-89fa86daa3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(file_path, encoding='unicode_escape')\n",
    "\n",
    "# Convert InvoiceDate to datetime\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# Drop rows with missing CustomerID\n",
    "df = df.dropna(subset=['CustomerID'])\n",
    "\n",
    "# Set snapshot date as one day after the last purchase\n",
    "snapshot_date = df['InvoiceDate'].max() + pd.Timedelta(days=1)\n",
    "\n",
    "# Compute Recency\n",
    "recency_df = df.groupby('CustomerID')['InvoiceDate'].max().reset_index()\n",
    "recency_df['Recency'] = (snapshot_date - recency_df['InvoiceDate']).dt.days\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4fc738-cf9e-4c22-8dbe-7d2f64c7d384",
   "metadata": {},
   "source": [
    "### Frequency: Number of Invoices per Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474fa64-ac89-4335-928e-2d977a15e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of unique invoices per CustomerID\n",
    "frequency_df = df.groupby('CustomerID')['InvoiceNo'].nunique().reset_index()\n",
    "frequency_df.columns = ['CustomerID', 'Frequency']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64cc146-0354-4711-be41-c1f8af18109a",
   "metadata": {},
   "source": [
    "### Monetary: Total Spend per Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425b995b-c5ab-4460-a577-b09e20b18dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Total Price\n",
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
    "\n",
    "# Aggregate total spend per customer\n",
    "monetary_df = df.groupby('CustomerID')['TotalPrice'].sum().reset_index()\n",
    "monetary_df.columns = ['CustomerID', 'Monetary']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c0ebe5-fd90-437e-8962-908fef38f396",
   "metadata": {},
   "source": [
    "### Merge RFM Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6e09c-fd6b-4951-999c-08e743e0ff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Recency, Frequency, and Monetary\n",
    "rfm = recency_df.merge(frequency_df, on='CustomerID') \\\n",
    "                .merge(monetary_df, on='CustomerID')\n",
    "\n",
    "rfm = rfm[['CustomerID', 'Recency', 'Frequency', 'Monetary']]\n",
    "rfm.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd319a6d-823a-499e-ba27-f696b6588f21",
   "metadata": {},
   "source": [
    "### Outlier Removal using Z-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0367e089-1ae2-4d4b-b37b-e3bd7d5c67ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Copy without CustomerID for filtering\n",
    "rfm_clean = rfm[['Recency', 'Frequency', 'Monetary']].copy()\n",
    "\n",
    "# Calculate Z-scores\n",
    "z_scores = np.abs(stats.zscore(rfm_clean))\n",
    "rfm_clean = rfm_clean[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Optional: keep only rows with matching CustomerIDs\n",
    "rfm = rfm.loc[rfm_clean.index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c068435-61bc-4108-a9e9-076de5fb19d3",
   "metadata": {},
   "source": [
    "###  Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0280fa76-eab0-4cf7-99a7-63440284dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize Recency, Frequency, Monetary\n",
    "scaler = StandardScaler()\n",
    "scaled_array = scaler.fit_transform(rfm[['Recency', 'Frequency', 'Monetary']])\n",
    "\n",
    "# Create final scaled dataframe\n",
    "rfm_scaled = pd.DataFrame(scaled_array, \n",
    "                          columns=['Recency', 'Frequency', 'Monetary'],\n",
    "                          index=rfm.index)\n",
    "\n",
    "rfm_scaled.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c395da37-599e-4b90-9f71-11c70c4aa082",
   "metadata": {},
   "source": [
    "## Building the Customer Segmentation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89724148-9c24-4a60-b79c-4dc833410fad",
   "metadata": {},
   "source": [
    "\n",
    "#### Building the Customer Segmentation Model with K-Means\n",
    "\n",
    "As mentioned earlier, we will now use the **K-Means clustering algorithm** to perform customer segmentation.\n",
    "\n",
    "The main objective of a K-Means model is to **group customers into distinct, non-overlapping clusters** based on their behavior ‚Äî in this case, derived from their **Recency, Frequency, and Monetary** values.\n",
    "\n",
    "Each cluster represents a group of customers that exhibit similar purchasing patterns, making it easier for businesses to tailor their marketing strategies.\n",
    "\n",
    "\n",
    "#### üåÄ What is K-Means Clustering?\n",
    "\n",
    "**K-Means** is an unsupervised machine learning algorithm that:\n",
    "\n",
    "1. Selects `k` cluster centroids randomly.\n",
    "2. Assigns each data point to the nearest centroid based on distance (usually Euclidean).\n",
    "3. Recomputes the centroids based on the new assignments.\n",
    "4. Repeats steps 2 and 3 until the centroids stop changing significantly.\n",
    "\n",
    "This results in **well-separated segments**, where members within each group are similar to each other and different from those in other groups.\n",
    "\n",
    "\n",
    "\n",
    "üìå **Visual Representation:**\n",
    "\n",
    "Below is a simplified visualization of how K-Means separates data into clusters:\n",
    "\n",
    "```\n",
    "\n",
    "‚¨§‚¨§‚¨§        ‚óØ‚óØ‚óØ        ‚ñ≤‚ñ≤‚ñ≤\n",
    "‚¨§‚¨§‚¨§   ‚Üí   ‚óØ‚óØ‚óØ   ‚Üí   ‚ñ≤‚ñ≤‚ñ≤\n",
    "‚¨§‚¨§‚¨§        ‚óØ‚óØ‚óØ        ‚ñ≤‚ñ≤‚ñ≤\n",
    "\n",
    "```\n",
    "\n",
    "Each symbol represents a different segment formed by the algorithm.  \n",
    "We‚Äôll now apply this technique to our standardized RFM dataset.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5bf831-a716-4689-91f3-ce0f289596d6",
   "metadata": {},
   "source": [
    "- **Now that the RFM features are standardized, we‚Äôll:**\n",
    "\n",
    "> Use the Elbow Method to choose the optimal number of clusters (K)\n",
    "\n",
    "> Apply K-Means Clustering\n",
    "\n",
    "> Attach cluster labels to each customer\n",
    "\n",
    "> Analyze and visualize the segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd11cb-f576-46df-ab34-c57c7bc337dc",
   "metadata": {},
   "source": [
    "### Elbow Method to Choose Optimal K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d04346-8d78-45a2-b100-1d77df755db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Elbow Method for Optimal K\n",
    "import os\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Optional: Suppress MKL & threading-related warnings\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Sum of Squared Errors for different cluster counts\n",
    "SSE = []\n",
    "\n",
    "# Try K values from 1 to 10\n",
    "for cluster in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=cluster, init='k-means++', random_state=42)\n",
    "    kmeans.fit(rfm_scaled)  # rfm_scaled is the standardized RFM dataset\n",
    "    SSE.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow Curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, 11), SSE, marker='o', linestyle='-')\n",
    "plt.title('Elbow Method for Optimal K')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia (SSE)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db5359c-7ef8-473e-9351-85f2ea6774fc",
   "metadata": {},
   "source": [
    "### Fit KMeans Model (k = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0e3ea5-7600-4b2f-b5ab-ef93f7a27458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå 4.2 Fit KMeans Model (Assuming k=4)\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Fit the KMeans model\n",
    "kmeans = KMeans(n_clusters=4, init='k-means++', random_state=42)\n",
    "kmeans.fit(rfm_scaled)\n",
    "\n",
    "# Assign cluster labels\n",
    "rfm_scaled['Cluster'] = kmeans.labels_\n",
    "rfm['Cluster'] = kmeans.labels_\n",
    "\n",
    "# View cluster counts\n",
    "rfm['Cluster'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb676783-ced5-4d2e-af4d-75d67e296d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìå 4.3 Assign Human-Readable Segment Labels Based on Cluster Characteristics\n",
    "\n",
    "# Revised: Map cluster numbers to strategically accurate segment names based on RFM behavior\n",
    "segment_map = {\n",
    "    0: \"Moderate Buyers\",       # Low frequency, moderate spend ‚Üí originally mislabeled\n",
    "    1: \"Top Spenders\",          # High frequency, high monetary ‚Üí this is your power cluster\n",
    "    2: \"New Customers\",         # Recent but not very frequent\n",
    "    3: \"At-Risk or Dormant\"     # Old recency, low frequency/spend\n",
    "}\n",
    "\n",
    "# Apply the mapping to your RFM DataFrame\n",
    "rfm['Segment'] = rfm['Cluster'].map(segment_map)\n",
    "\n",
    "# Optional: Inspect segment-wise average RFM values to validate logic\n",
    "rfm.groupby('Segment')[['Recency', 'Frequency', 'Monetary']].mean().round(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d85704-d5fa-4036-b970-e64dbcacd8e6",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Segment Strategy Summary\n",
    "\n",
    "| Segment Name       | Description                                    | Recommended Action                              |\n",
    "|--------------------|------------------------------------------------|--------------------------------------------------|\n",
    "| Top Spenders       | Very frequent, very high spend buyers          | VIP loyalty programs, early access offers        |\n",
    "| Moderate Buyers    | Low frequency, moderate spend                  | Targeted upsell emails, time-limited coupons     |\n",
    "| New Customers      | Recent purchases, moderate frequency/spend     | Onboarding flow, email welcome sequence          |\n",
    "| At-Risk or Dormant | Old recency, low frequency and spend           | Win-back campaigns, personalized reactivation    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c2b285-e573-4bf2-ae68-34b11799c4e3",
   "metadata": {},
   "source": [
    "### ü§ñ 4.4 AI-Ready Segment Predictor (ML Classifier)\n",
    "\n",
    "After assigning strategic labels to clusters (`rfm['Segment']`), we build a machine learning model to **automatically classify new customers** into the correct segments based on their RFM values. This enables real-time, scalable customer segmentation powered by AI.\n",
    "\n",
    "### üõ†Ô∏è Model Overview\n",
    "- **Model**: Random Forest Classifier\n",
    "- **Features**: Recency, Frequency, Monetary\n",
    "- **Target**: Segment labels\n",
    "- **Split**: Stratified 80/20 train-test\n",
    "\n",
    "### üìä Model Evaluation\n",
    "- Achieved **>96% macro F1-score** across all segments\n",
    "- Ensured class balance with `stratify=y` during split\n",
    "- Enables deployment-ready segment predictions\n",
    "\n",
    "### ‚úÖ Use Cases\n",
    "- Assign segments to new customers on-the-fly\n",
    "- Personalize offers, emails, and promotions\n",
    "- Plug into dashboards or CRM systems via saved model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde59fa6-c522-4875-9f68-b7ef5ef5338b",
   "metadata": {},
   "source": [
    "### AI-Ready Segment Predictor (ML Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efa271c-f4c3-476c-91b3-3d04a6f25746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 1. Prepare data\n",
    "X = rfm[['Recency', 'Frequency', 'Monetary']]\n",
    "y = rfm['Segment']\n",
    "\n",
    "# 2. Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)\n",
    "\n",
    "# 3. Train model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate\n",
    "y_pred = rf_model.predict(X_test)\n",
    "print(\"üìä Segment Prediction Performance:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8257ff05-2785-4ebf-9d5e-2c79046f5682",
   "metadata": {},
   "source": [
    "### Visualize the Clusters (Pairplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc52421a-1371-471d-b008-8ee8c13cd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä 4.3 Visualize the Clusters (Pairplot)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pairplot of standardized features with clusters\n",
    "sns.pairplot(rfm_scaled, hue='Cluster', palette='Set2', diag_kind='kde')\n",
    "plt.suptitle(\"Customer Segments (Standardized RFM)\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fe6efa-fd91-43a5-952d-a76fc55e5bcf",
   "metadata": {},
   "source": [
    "### Visualize Clusters in 2D using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9af54a7-d0ad-4afd-b73b-fc68a4be028c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìâ 4.4 Visualize Clusters in 2D using PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensions to 2D\n",
    "pca = PCA(n_components=2)\n",
    "components = pca.fit_transform(rfm_scaled.drop(columns='Cluster'))\n",
    "\n",
    "# Add to dataframe\n",
    "rfm_scaled['PCA1'] = components[:, 0]\n",
    "rfm_scaled['PCA2'] = components[:, 1]\n",
    "\n",
    "# Scatterplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(data=rfm_scaled, x='PCA1', y='PCA2', hue='Cluster', palette='Set2', s=70)\n",
    "plt.title('PCA Projection of Customer Clusters')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dfe314-5b48-4f39-b492-1b97a990d87d",
   "metadata": {},
   "source": [
    "### Assign Human-Readable Cluster Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ad65d8-0fd3-45d3-b48f-486d15d45bd0",
   "metadata": {},
   "source": [
    "#### Create a Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8ac029-f7a5-484a-bb1a-a6b984014bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üè∑Ô∏è Map each cluster to a human-readable label\n",
    "cluster_labels = {\n",
    "    0: \"New Customers\",\n",
    "    1: \"High-Value Loyalists\",\n",
    "    2: \"Frequent Budget Buyers\",\n",
    "    3: \"At-Risk or Dormant\"\n",
    "}\n",
    "\n",
    "# Add named label column\n",
    "rfm['Segment'] = rfm['Cluster'].map(cluster_labels)\n",
    "rfm_scaled['Segment'] = rfm_scaled['Cluster'].map(cluster_labels)\n",
    "\n",
    "# Preview updated DataFrame\n",
    "rfm[['CustomerID', 'Recency', 'Frequency', 'Monetary', 'Cluster', 'Segment']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066402c2-3903-4cec-a15b-7ed1e2605978",
   "metadata": {},
   "source": [
    "### Radar (Spider) Plot for Cluster Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181738a1-0089-46b4-8000-9f1c89ad119d",
   "metadata": {},
   "source": [
    "> This visual helps compare Recency, Frequency, and Monetary scores side-by-side across all segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7ae9c8-2fd5-406b-a61b-3a4734fa2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÅ Radar Chart with Updated Segment Labels\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Prepare data\n",
    "rfm_means = rfm.groupby('Segment')[['Recency', 'Frequency', 'Monetary']].mean()\n",
    "rfm_scaled = (rfm_means - rfm_means.min()) / (rfm_means.max() - rfm_means.min())\n",
    "\n",
    "# Setup\n",
    "labels = rfm_scaled.columns\n",
    "angles = np.linspace(0, 2*np.pi, len(labels), endpoint=False).tolist() + [0]\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Plot\n",
    "for idx, (segment, row) in enumerate(rfm_scaled.iterrows()):\n",
    "    values = row.tolist() + [row.tolist()[0]]\n",
    "    ax.plot(angles, values, label=segment, linewidth=2)\n",
    "    ax.fill(angles, values, alpha=0.15)\n",
    "\n",
    "# Format\n",
    "ax.set_title(\" RFM Radar Chart by Segment (Strategic Labels)\", size=14, pad=20)\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(labels, fontsize=12)\n",
    "ax.set_yticklabels([])\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a35297-e64a-48af-9c9d-77336299b267",
   "metadata": {},
   "source": [
    "## Summary of Steps: Customer Segmentation with RFM & K-Means\n",
    "\n",
    "| Step No. | Description                                                                 |\n",
    "|----------|------------------------------------------------------------------------------|\n",
    "| 1Ô∏è‚É£       | Loaded e-commerce transactional dataset using `pandas`                     |\n",
    "| 2Ô∏è‚É£       | Extracted and calculated **RFM** (Recency, Frequency, Monetary) metrics     |\n",
    "| 3Ô∏è‚É£       | Removed outliers using **Z-score filtering** to ensure clean input data     |\n",
    "| 4Ô∏è‚É£       | Standardized RFM features using `StandardScaler` for K-Means compatibility  |\n",
    "| 5Ô∏è‚É£       | Used the **Elbow Method** to determine the optimal number of clusters (`k`) |\n",
    "| 6Ô∏è‚É£       | Applied **KMeans clustering** with `k=4` to segment customers               |\n",
    "| 7Ô∏è‚É£       | Visualized clusters using a **Seaborn pairplot**                            |\n",
    "| 8Ô∏è‚É£       | Projected customer segments in 2D using **PCA scatterplot**                 |\n",
    "| 9Ô∏è‚É£       | Mapped numeric clusters to **human-readable segment names**                 |\n",
    "| üîü       | Created a **Radar Chart** to compare behavioral traits across segments       |\n",
    "| ‚úÖ       | Exported final labeled RFM dataset with clusters to CSV                      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fdc925-2ecd-4380-bca7-16d5f1af33cb",
   "metadata": {},
   "source": [
    "### Business Framing of Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eda8f68-9d52-41aa-bc24-dc9085d2cbcb",
   "metadata": {},
   "source": [
    ">üéØ Goal:\n",
    "Give each segment strategic purpose ‚Äî what action should be taken on them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a5c983-38eb-4111-a6ba-77598b658225",
   "metadata": {},
   "source": [
    "## üéØ Segment Strategy Summary\n",
    "\n",
    "| Segment Name        | Description                                       | Recommended Action                                       |\n",
    "|---------------------|---------------------------------------------------|-----------------------------------------------------------|\n",
    "| **Top Spenders**     | High frequency, high monetary buyers              | Prioritize for premium offerings, loyalty incentives      |\n",
    "| **Moderate Buyers**  | Moderate frequency and spend                      | Encourage cross-sells and higher-value conversions        |\n",
    "| **New Customers**    | Recent but not yet very frequent buyers           | Nurture with onboarding campaigns and product tours       |\n",
    "| **At-Risk or Dormant** | Low frequency/spend, older recency              | Launch re-engagement emails, reminders, and incentives    |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab084a63-9f6b-42c0-b4aa-1deee5430160",
   "metadata": {},
   "source": [
    "- Tailor this to your clusters using actual rfm.groupby('Segment').mean() values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b23701-8803-4861-8651-e03ecd81692b",
   "metadata": {},
   "source": [
    "### Strategic Applications for YouTube BizOps (Role-Aligned Framing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaec5bdb-0fcc-4997-badd-ec75ab74511e",
   "metadata": {},
   "source": [
    "\n",
    "## üíº Strategic Applications\n",
    "\n",
    "This segmentation model can support YouTube's Partner Management operations in the following ways:\n",
    "\n",
    "- üéØ **Targeted Partner Support**: Assign more experienced Partner Managers to ‚ÄúTop Spenders‚Äù to ensure continued growth and reduce churn risk.\n",
    "- üß™ **Experiment Prioritization**: Run onboarding and A/B test initiatives on ‚ÄúNew Customers‚Äù to accelerate frequency and spend behavior.\n",
    "- üîÅ **Retention Campaigns**: Trigger automated re-engagement workflows for ‚ÄúAt-Risk or Dormant‚Äù partners, combining email and in-app messaging.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc885d1-954b-4397-b8b4-83cc850f3427",
   "metadata": {},
   "source": [
    "## üìå Final Summary & Next Steps\n",
    "\n",
    "In this notebook, we:\n",
    "\n",
    "- Performed **RFM-based customer segmentation** using K-Means\n",
    "- Interpreted clusters using segment-wise means and radar charts\n",
    "- Trained an **AI-ready segment classifier** for real-time applications\n",
    "- Proposed strategic and operational use cases for each segment\n",
    "\n",
    "**Next Steps**:\n",
    "- Deploy this model to score YouTube partners dynamically\n",
    "- Integrate segment-based strategies into business decision-making\n",
    "- Extend to multi-channel behavior (e.g., video views, CTR, NPS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ee51a0-e318-4170-9d9a-7bbf6344d122",
   "metadata": {},
   "source": [
    "## Code for creating the pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed9274b-57b3-42ef-ac46-712e3a995a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarat\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\sarat\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "        \"wmic CPU Get NumberOfCores /Format:csv\".split(),\n",
      "        capture_output=True,\n",
      "        text=True,\n",
      "    )\n",
      "  File \"C:\\Users\\sarat\\anaconda3\\Lib\\subprocess.py\", line 554, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sarat\\anaconda3\\Lib\\subprocess.py\", line 1039, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        pass_fds, cwd, env,\n",
      "                        ^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "                        gid, gids, uid, umask,\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^\n",
      "                        start_new_session, process_group)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sarat\\anaconda3\\Lib\\subprocess.py\", line 1554, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^\n",
      "                             # no special security\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "                             cwd,\n",
      "                             ^^^^\n",
      "                             startupinfo)\n",
      "                             ^^^^^^^^^^^^\n",
      "C:\\Users\\sarat\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=17.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Both models trained and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Load RFM data\n",
    "rfm = pd.read_csv(\"sample_rfm.csv\")\n",
    "\n",
    "# Step 1: Scale the features for KMeans\n",
    "features = ['Recency', 'Frequency', 'Monetary']\n",
    "scaler = StandardScaler()\n",
    "rfm_scaled = scaler.fit_transform(rfm[features])\n",
    "\n",
    "# Step 2: Train KMeans\n",
    "kmeans = KMeans(n_clusters=4, random_state=42, n_init=10)\n",
    "rfm['Cluster'] = kmeans.fit_predict(rfm_scaled)\n",
    "\n",
    "# Save the KMeans model\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(kmeans, \"models/kmeans_model.pkl\")\n",
    "\n",
    "# Step 3: Train RandomForestClassifier to predict clusters\n",
    "X = rfm[features]\n",
    "y = rfm['Cluster']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Save the Random Forest model\n",
    "joblib.dump(rf_classifier, \"models/rf_classifier.pkl\")\n",
    "\n",
    "print(\"‚úÖ Both models trained and saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b9533e1-62a3-48b2-98dd-b4d09f00e028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\sarat\\anaconda3\\lib\\site-packages (1.45.1)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (2.1.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (2.2.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (4.14.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (4.0.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9efd5e86-6f6a-45c0-8dd1-cf201d987bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\sarat\\anaconda3\\lib\\site-packages (1.45.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\sarat\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\sarat\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\sarat\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: altair in c:\\users\\sarat\\anaconda3\\lib\\site-packages (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (5.5.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (2.1.3)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (24.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (11.1.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (19.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (4.14.0)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (4.0.2)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (3.1.43)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from streamlit) (6.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from altair) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from altair) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from altair) (1.31.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.7)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair) (24.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair) (0.22.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sarat\\anaconda3\\lib\\site-packages (from jinja2->altair) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit pandas scikit-learn matplotlib altair\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
